#!/usr/bin/env python
# Copyright 2021 The StackStorm Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Migration which which migrates data for existing objects in the database which utilize
EscapedDictField or EscapedDynamicField and have been updated to use new JsonDictField.

Migration step is idempotent and can be retried on failures / partial runs.

Keep in mind that running this migration script is optional and it may take a long time of you have
a lot of very large objects in the database (aka executions) - reading a lot of data from the
database using the old field types is slow and CPU intensive.

New field type is automatically used for all the new objects when upgrading to v3.5 so migration is
optional because in most cases users are viewing recent / new executions and not old ones which may
still utilize old field typo which is slow to read / write.

Right now the script utilizes no concurrency and performs migration one object by one. That's done
for simplicity reasons and also to avoid massive CPU usage spikes when running this script with
large concurrency on large objects.

Keep in mind that only "completed" objects are processes - this means Executions in "final" states
(succeeded, failed, timeout, etc.).

We determine if an object should be migrating using mongodb $type query (for execution objects we
could also determine that based on the presence of result_size field).
"""

import sys
import time
import traceback

from st2common import config
from st2common.service_setup import db_setup
from st2common.service_setup import db_teardown
from st2common.models.db.execution import ActionExecutionDB
from st2common.models.db.workflow import WorkflowExecutionDB
from st2common.models.db.workflow import TaskExecutionDB
from st2common.models.db.trigger import TriggerInstanceDB
from st2common.persistence.execution import ActionExecution
from st2common.persistence.liveaction import LiveAction
from st2common.persistence.workflow import WorkflowExecution
from st2common.persistence.workflow import TaskExecution
from st2common.persistence.trigger import TriggerInstance
from st2common.exceptions.db import StackStormDBObjectNotFoundError
from st2common.constants.action import LIVEACTION_COMPLETED_STATES
from st2common.constants.triggers import TRIGGER_INSTANCE_COMPLETED_STATES


def migrate_executions() -> None:
    """
    Perform migrations for execution related objects (ActionExecutionDB, LiveActionDB).
    """
    print("Migrating execution objects")

    # NOTE: We first only retrieve the IDs because there could be a lot of objects in the database
    # and this could result in massive ram use. Technically, mongoengine loads querysets lazily,
    # but this is not always the case so it's better to first retrieve all the IDs and then retrieve
    # objects one by one.
    # Keep in mind we need to use ModelClass.objects and not PersistanceClass.query() so .only()
    # works correctly - with PersistanceClass.query().only() all the fields will still be retrieved.

    # 1. Migrate ActionExecutionDB objects
    execution_dbs = ActionExecutionDB.objects(
        __raw__={
            "result": {
                "$not": {
                    "$type": "binData",
                },
            },
            "status": {
                "$in": LIVEACTION_COMPLETED_STATES,
            },
        },
    ).only("id")
    execution_ids = [str(execution_db.id) for execution_db in execution_dbs]

    if not execution_ids:
        print("Found no ActionExecutionDB objects to migrate.")
        return None

    print("Will migrate %s ActionExecutionDB objects" % (len(execution_ids)))
    print("")

    for execution_id in execution_ids:
        try:
            execution_db = ActionExecution.get_by_id(execution_id)
        except StackStormDBObjectNotFoundError:
            print(
                "Skipping ActionExecutionDB with id %s which is missing in the database"
                % (execution_id)
            )
            continue

        print("Migrating ActionExecutionDB with id %s" % (execution_id))

        # This is a bit of a "hack", but it's the easiest way to tell mongoengine that a specific
        # field has been updated and should be saved. If we don't do, nothing will be re-saved on
        # .save() call due to mongoengine only trying to save what has changed to make it more
        # efficient instead of always re-saving the whole object.
        execution_db._mark_as_changed("result")
        execution_db._mark_as_changed("result_size")

        #  print(getattr(execution_db, "_changed_fields", []))
        execution_db.save()
        print("ActionExecutionDB with id %s has been migrated" % (execution_db.id))

        # Migrate corresponding LiveAction object
        liveaction = execution_db.liveaction or {}
        liveaction_id = liveaction.get("id", None)

        if not liveaction_id:
            continue

        try:
            liveaction_db = LiveAction.get_by_id(liveaction_id)
        except StackStormDBObjectNotFoundError:
            # If liveaction for some reason doesn't exist (would likely represent corrupted data) we
            # simply ignore that error since it's not fatal.
            print(
                "Skipping LiveActionDB with id %s which is missing in the database"
                % (liveaction_db)
            )
            continue

        liveaction_db._mark_as_changed("result")

        # print(getattr(liveaction_db, "_changed_fields", []))
        liveaction_db.save()
        print("Related LiveActionDB with id %s has been migrated" % (liveaction_db.id))
        print("")


def migrate_workflow_objects() -> None:
    print("Migrating workflow objects")

    # 1. Migrate WorkflowExecutionDB
    workflow_execution_dbs = WorkflowExecutionDB.objects(
        __raw__={
            "output": {
                "$not": {
                    "$type": "binData",
                },
            },
            "status": {
                "$in": LIVEACTION_COMPLETED_STATES,
            },
        }
    ).only("id")
    workflow_execution_ids = [
        str(workflow_execution_db.id)
        for workflow_execution_db in workflow_execution_dbs
    ]

    if not workflow_execution_ids:
        print("Found no WorkflowExecutionDB objects to migrate.")
    else:
        print(
            "Will migrate %s WorkflowExecutionDB objects"
            % (len(workflow_execution_ids))
        )
        print("")

    for workflow_execution_id in workflow_execution_ids or []:
        try:
            workflow_execution_db = WorkflowExecution.get_by_id(workflow_execution_id)
        except StackStormDBObjectNotFoundError as e:
            print(
                "Skipping WorkflowExecutionDB with id %s which is missing in the database"
                % (workflow_execution_id)
            )
            continue

        print("Migrating WorkflowExecutionDB with id %s" % (workflow_execution_db.id))

        workflow_execution_db._mark_as_changed("input")
        workflow_execution_db._mark_as_changed("context")
        workflow_execution_db._mark_as_changed("state")
        workflow_execution_db._mark_as_changed("output")

        workflow_execution_db.save()
        print(
            "WorkflowExecutionDB with id %s has been migrated"
            % (workflow_execution_db.id)
        )
        print("")

    # 2. Migrate TaskExecutionDB
    task_execution_dbs = TaskExecutionDB.objects(
        __raw__={
            "result": {
                "$not": {
                    "$type": "binData",
                },
            },
            "status": {
                "$in": LIVEACTION_COMPLETED_STATES,
            },
        }
    ).only("id")
    task_execution_ids = [
        str(task_execution_db.id) for task_execution_db in task_execution_dbs
    ]

    if not task_execution_ids:
        print("Found no TaskExecutionDB objects to migrate.")
    else:
        print("Will migrate %s TaskExecutionDB objects" % (len(task_execution_ids)))
        print("")

    for task_execution_id in task_execution_ids or []:
        try:
            task_execution_db = TaskExecution.get_by_id(task_execution_id)
        except StackStormDBObjectNotFoundError as e:
            print(
                "Skipping TaskExecutionDB with id %s which is missing in the database"
                % (task_execution_db)
            )
            continue

        print("Migrating TaskExecutionDB with id %s" % (task_execution_db.id))

        task_execution_db._mark_as_changed("task_spec")
        task_execution_db._mark_as_changed("context")
        task_execution_db._mark_as_changed("result")

        task_execution_db.save()
        print("TaskExecutionDB with id %s has been migrated" % (task_execution_db.id))
        print("")


def migrate_triggers() -> None:
    print("Migrating trigger objects")

    trigger_instance_dbs = TriggerInstanceDB.objects(
        __raw__={
            "payload": {
                "$not": {
                    "$type": "binData",
                },
            },
            "status": {
                "$in": TRIGGER_INSTANCE_COMPLETED_STATES,
            },
        }
    ).only("id")
    trigger_instance_ids = [
        str(trigger_instance_db.id) for trigger_instance_db in trigger_instance_dbs
    ]

    if not trigger_instance_ids:
        print("Found no TriggerInstanceDB objects to migrate.")
        return None

    print("Will migrate %s TriggerInstanceDB objects" % (len(trigger_instance_ids)))

    for trigger_instance_id in trigger_instance_ids or []:
        try:
            trigger_instance_db = TriggerInstance.get_by_id(trigger_instance_id)
        except StackStormDBObjectNotFoundError as e:
            print(
                "Skipping TriggerInstanceDB with id %s which is missing in the database"
                % (trigger_instance_id)
            )
            continue

        print("Migrating TriggerInstanceDB with id %s" % (trigger_instance_db.id))

        trigger_instance_db._mark_as_changed("payload")

        trigger_instance_db.save()
        print(
            "TriggerInstanceDB with id %s has been migrated" % (trigger_instance_db.id)
        )
        print("")


def migrate_objects(display_prompt: bool = True) -> None:
    print("StackStorm v3.5 database field data migration script\n")

    if display_prompt:
        input(
            "You are stronly recommended to create database backup before running the "
            "migration script.\n\nDepending on the number of the objects in the database, "
            "migration may take multiple hours or more. You are recommended to start the the "
            "script in a screen session or similar. \n\n"
            "To proceed with the migration, press enter and to cancel it, press CTRL+C."
        )
        print("")

    print("Migrating affected database objects to utilize new field type")
    print("")

    start_ts = int(time.time())
    migrate_executions()
    migrate_workflow_objects()
    migrate_triggers()
    end_ts = int(time.time())

    duration = end_ts - start_ts

    print("")
    print(
        "SUCCESS: All database objects migrated successfully (duration: %s seconds)."
        % (duration)
    )


def main():
    if "--yes" in sys.argv:
        sys.argv.remove("--yes")
        display_prompt = False
    else:
        display_prompt = True

    config.parse_args()
    db_setup()

    try:
        migrate_objects(display_prompt=display_prompt)
        exit_code = 0
    except Exception as e:
        print("ABORTED: Objects migration aborted on first failure: %s" % (str(e)))
        traceback.print_exc()
        exit_code = 1

    db_teardown()
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
